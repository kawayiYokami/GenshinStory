#!/usr/bin/env python3
"""
æ ‡ç­¾åˆ†æå·¥å…·

åˆ†æç¼“å­˜æ–‡ä»¶ä¸­çš„æ ‡ç­¾æ•°æ®ï¼Œè¾“å‡ºæ¯ä¸ªæ•°æ®ç±»å‹çš„æ‰€æœ‰å¯ç”¨æ ‡ç­¾å­—æ®µå’Œç»Ÿè®¡ä¿¡æ¯ï¼Œ
ä¾›ç”¨æˆ·é€‰æ‹©æœ€åˆé€‚çš„åˆ†ç±»å­—æ®µã€‚
"""

import os
import sys
import logging
from collections import defaultdict, Counter
from typing import Dict, List, Any, Set

# Setup project root path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)

from giwiki_data_parser.services.cache_service import CacheService

# é…ç½®
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
CACHE_FILE_PATH = "giwiki_data_parser/cache/giwiki_data.cache.gz"

def analyze_tags_for_data_type(data_list: List[Any], type_name: str) -> Dict[str, Any]:
    """åˆ†æå•ä¸ªæ•°æ®ç±»å‹çš„æ ‡ç­¾"""
    if not data_list:
        return {"type_name": type_name, "count": 0, "tag_analysis": {}}

    # ç»Ÿè®¡æ‰€æœ‰æ ‡ç­¾é”®å’Œå€¼
    tag_stats = defaultdict(Counter)
    items_with_tags = 0

    for item in data_list:
        if hasattr(item, 'tags') and item.tags:
            items_with_tags += 1
            for tag_key, tag_value in item.tags.items():
                if tag_value:  # åªç»Ÿè®¡éç©ºå€¼
                    tag_stats[tag_key][tag_value] += 1

    # æ•´ç†ç»Ÿè®¡ç»“æœ
    tag_analysis = {}
    for tag_key, value_counter in tag_stats.items():
        unique_values = len(value_counter)
        total_occurrences = sum(value_counter.values())
        most_common = value_counter.most_common(10)  # æ˜¾ç¤ºå‰10ä¸ªæœ€å¸¸è§çš„å€¼

        tag_analysis[tag_key] = {
            "unique_values": unique_values,
            "total_occurrences": total_occurrences,
            "coverage": total_occurrences / len(data_list) * 100,  # è¦†ç›–ç‡
            "most_common_values": most_common
        }

    return {
        "type_name": type_name,
        "total_items": len(data_list),
        "items_with_tags": items_with_tags,
        "tag_coverage": items_with_tags / len(data_list) * 100 if data_list else 0,
        "tag_analysis": tag_analysis
    }

def print_analysis_results(results: List[Dict[str, Any]]):
    """æ‰“å°åˆ†æç»“æœ"""
    print("=" * 80)
    print("æ ‡ç­¾åˆ†æç»“æœ")
    print("=" * 80)

    for result in results:
        if result["total_items"] == 0:
            continue

        print(f"\nğŸ“Š æ•°æ®ç±»å‹: {result['type_name']}")
        print(f"   æ€»é¡¹ç›®æ•°: {result['total_items']}")
        print(f"   æœ‰æ ‡ç­¾çš„é¡¹ç›®: {result['items_with_tags']} ({result['tag_coverage']:.1f}%)")

        if not result["tag_analysis"]:
            print("   âŒ æ— æ ‡ç­¾æ•°æ®")
            continue

        print(f"   ğŸ“‹ å¯ç”¨æ ‡ç­¾å­—æ®µ ({len(result['tag_analysis'])} ä¸ª):")

        # æŒ‰å”¯ä¸€å€¼æ•°é‡æ’åºï¼Œä¾¿äºé€‰æ‹©åˆé€‚çš„åˆ†ç±»å­—æ®µ
        sorted_tags = sorted(
            result["tag_analysis"].items(),
            key=lambda x: x[1]["unique_values"]
        )

        for tag_key, tag_info in sorted_tags:
            print(f"      ğŸ·ï¸  '{tag_key}':")
            print(f"         - å”¯ä¸€å€¼æ•°é‡: {tag_info['unique_values']}")
            print(f"         - è¦†ç›–ç‡: {tag_info['coverage']:.1f}%")
            print(f"         - å¸¸è§å€¼: {', '.join([f'{v}({c})' for v, c in tag_info['most_common_values'][:5]])}")

            # ç»™å‡ºåˆ†ç±»å»ºè®®
            unique_count = tag_info['unique_values']
            coverage = tag_info['coverage']

            if 2 <= unique_count <= 20 and coverage >= 80:
                print(f"         âœ… æ¨èç”¨äºåˆ†ç±» (å€¼æ•°é‡é€‚ä¸­ï¼Œè¦†ç›–ç‡é«˜)")
            elif unique_count > 50:
                print(f"         âš ï¸  å€¼è¿‡å¤šï¼Œä¸é€‚åˆåˆ†ç±»")
            elif coverage < 50:
                print(f"         âš ï¸  è¦†ç›–ç‡ä½ï¼Œä¸é€‚åˆåˆ†ç±»")
            elif unique_count == 1:
                print(f"         âŒ åªæœ‰ä¸€ä¸ªå€¼ï¼Œæ— æ³•åˆ†ç±»")
            else:
                print(f"         ğŸ¤” å¯è€ƒè™‘ç”¨äºåˆ†ç±»")

def main():
    """ä¸»å‡½æ•°"""
    if not os.path.exists(CACHE_FILE_PATH):
        print(f"âŒ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {CACHE_FILE_PATH}")
        print("è¯·å…ˆè¿è¡Œ scripts/giwiki_create_cache.py åˆ›å»ºç¼“å­˜")
        sys.exit(1)

    print(f"ğŸ“‚ åŠ è½½ç¼“å­˜æ–‡ä»¶: {CACHE_FILE_PATH}")
    try:
        cache_service = CacheService.load(CACHE_FILE_PATH)
        print("âœ… ç¼“å­˜åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åŠ è½½ç¼“å­˜å¤±è´¥: {e}")
        sys.exit(1)

    # è·å–æ‰€æœ‰æ•°æ®ç±»å‹
    data_types = [
        ("characters", cache_service.characters),
        ("weapons", cache_service.weapons),
        ("artifacts", cache_service.artifacts),
        ("enemies", cache_service.enemies),
        ("animals", cache_service.animals),
        ("inventory_items", cache_service.inventory_items),
        ("npc_shops", cache_service.npc_shops),
        ("organizations", cache_service.organizations),
        ("character_stories", cache_service.character_stories),
        ("map_texts", cache_service.map_texts),
        ("foods", cache_service.foods),
        ("domains", cache_service.domains),
        ("outfits", cache_service.outfits),  # æ–°å¢çš„è£…æ‰®ç±»å‹
        ("quests", cache_service.quests),
        ("books", cache_service.books),
    ]

    # åˆ†ææ¯ä¸ªæ•°æ®ç±»å‹
    results = []
    for type_name, data_list in data_types:
        print(f"ğŸ” åˆ†æ {type_name}...")
        result = analyze_tags_for_data_type(data_list, type_name)
        results.append(result)

    # æ‰“å°ç»“æœ
    print_analysis_results(results)

    print("\n" + "=" * 80)
    print("ğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("1. é€‰æ‹© 'âœ… æ¨èç”¨äºåˆ†ç±»' çš„æ ‡ç­¾å­—æ®µ")
    print("2. ä¼˜å…ˆé€‰æ‹©å”¯ä¸€å€¼æ•°é‡åœ¨ 2-20 ä¹‹é—´çš„å­—æ®µ")
    print("3. ä¼˜å…ˆé€‰æ‹©è¦†ç›–ç‡é«˜çš„å­—æ®µ")
    print("4. è€ƒè™‘è¯­ä¹‰ä¸Šæœ‰åˆ†ç±»æ„ä¹‰çš„å­—æ®µ")
    print("=" * 80)

if __name__ == "__main__":
    main()